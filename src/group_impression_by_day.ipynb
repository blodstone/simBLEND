{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6333ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from pymilvus import MilvusClient\n",
    "from pymilvus import CollectionSchema, FieldSchema, DataType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9d2f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news_data = None\n",
    "dev_news_data = None\n",
    "aspect_vector_dir = Path('/mount/arbeitsdaten66/projekte/multiview/hardy/project/vae/outputs/mind')\n",
    "MIND_dev_path = Path('/mount/arbeitsdaten66/projekte/multiview/hardy/datasets/mind_resplit/MINDlarge_dev')\n",
    "MIND_train_path = Path('/mount/arbeitsdaten66/projekte/multiview/hardy/datasets/mind_resplit/MINDlarge_train')\n",
    "MIND_test_path = Path('/mount/arbeitsdaten66/projekte/multiview/hardy/datasets/mind_resplit/MINDlarge_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad30e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_aspect_vectors(path: Path):\n",
    "    \"\"\"\n",
    "    Load aspect vectors from a given path.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            nid = int(parts[0])\n",
    "            vector = [float(x) for x in parts[1:]]\n",
    "            data[nid] = np.array(vector, dtype=np.float32)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db43fd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_vectors = {\n",
    "    'dev': {\n",
    "        'std': load_aspect_vectors(aspect_vector_dir / 'dev_mind_std_sts_aspect_vectors.txt'),\n",
    "        'frame': load_aspect_vectors(aspect_vector_dir / 'dev_mind_frame_aspect_vectors.txt'),\n",
    "        'cat': load_aspect_vectors(aspect_vector_dir / 'dev_mind_category_aspect_vectors.txt'),\n",
    "        'political': load_aspect_vectors(aspect_vector_dir / 'dev_mind_political_aspect_vectors.txt'),\n",
    "        'sentiment': load_aspect_vectors(aspect_vector_dir / 'dev_mind_sentiment_aspect_vectors.txt'),\n",
    "    },\n",
    "    'test': {\n",
    "        'std': load_aspect_vectors(aspect_vector_dir / 'test_mind_std_sts_aspect_vectors.txt'),\n",
    "        'frame': load_aspect_vectors(aspect_vector_dir / 'test_mind_frame_aspect_vectors.txt'),\n",
    "        'cat': load_aspect_vectors(aspect_vector_dir / 'test_mind_category_aspect_vectors.txt'),\n",
    "        'political': load_aspect_vectors(aspect_vector_dir / 'test_mind_political_aspect_vectors.txt'),\n",
    "        'sentiment': load_aspect_vectors(aspect_vector_dir / 'test_mind_sentiment_aspect_vectors.txt'),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "970c0a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1115727774a341479c0a1cf831791eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aspects = ['std', 'cat', 'frame', 'political', 'sentiment']\n",
    "combined_aspect_vectors = {}\n",
    "for split, item in tqdm(aspect_vectors.items()):\n",
    "    combined_aspect_vectors[split] = {}\n",
    "    for aspect, vector in item.items():\n",
    "        for nid, vec in vector.items():\n",
    "            if nid not in combined_aspect_vectors[split]:\n",
    "                combined_aspect_vectors[split][nid] = [None for i in range(len(aspects))]\n",
    "            combined_aspect_vectors[split][nid][aspects.index(aspect)] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e79bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split, item in combined_aspect_vectors.items():\n",
    "    for nid, vec in item.items():\n",
    "        assert len(vec) == len(aspects), f\"Vector length mismatch for nid {nid} in split {split}\"\n",
    "        vec = np.concatenate(vec, axis=0)\n",
    "        combined_aspect_vectors[split][nid] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "034b5b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_history(df_behaviors):\n",
    "    \"\"\"\n",
    "    MIND dataset has a bug where rows with the same user_id has similar history. This function will fix\n",
    "    it by appending the user history with the clicked articles of previous impression for each user. \n",
    "    \"\"\"\n",
    "    df_behaviors['timestamp'] = pd.to_datetime(df_behaviors['timestamp'])\n",
    "    df_behaviors['history'] = df_behaviors['history'].apply(lambda x: x.split() if type(x) == str else [])\n",
    "    cal_history = {}\n",
    "    for user_id, group in tqdm(df_behaviors.sort_values(by=['user_id', 'timestamp']).groupby('user_id')):\n",
    "        cum_history = []\n",
    "        for i, (index, row) in enumerate(group.iterrows()):\n",
    "            if i != 0:\n",
    "                row['history'].extend(cum_history)\n",
    "                impression = [i.split('-')[0] for i in row['impressions'].split() if i.endswith('-1')]\n",
    "                cum_history.extend(impression)\n",
    "            else:\n",
    "                cum_history = [i.split('-')[0] for i in row['impressions'].split() if i.endswith('-1')]\n",
    "            cal_history[index] = row['history']\n",
    "    history_series = pd.Series(cal_history)\n",
    "    df_behaviors['history'] = history_series\n",
    "    df_behaviors['history'] = df_behaviors['history'].apply(lambda x: ' '.join(x))\n",
    "    last_user_rows = df_behaviors.sort_values(by='timestamp').groupby('user_id').tail(1)\n",
    "    return last_user_rows\n",
    "\n",
    "def load_and_fix_df(path):\n",
    "    df_behaviors = pd.read_csv(path / \"behaviors.tsv\", header=None, sep='\\t')\n",
    "    df_behaviors.columns = ['impression_id', 'user_id', 'timestamp', 'history', 'impressions']\n",
    "    df_behaviors['timestamp'] = pd.to_datetime(df_behaviors['timestamp'])\n",
    "    df_behaviors = append_history(df_behaviors)\n",
    "    return df_behaviors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c79a5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcf7f158a664835b560af934fb22035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/654870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c411f976314c7da54f7c15a10ef490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762aaf7f477447eda621647997054af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/255990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = load_and_fix_df(MIND_train_path)\n",
    "df_dev = load_and_fix_df(MIND_dev_path)\n",
    "df_test = load_and_fix_df(MIND_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae3f0cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "Earliest timestamp: 2019-11-09 00:00:03\n",
      "Latest timestamp: 2019-11-13 23:59:57\n",
      "\n",
      "Dev set:\n",
      "Earliest timestamp: 2019-11-14 00:00:00\n",
      "Latest timestamp: 2019-11-14 23:59:59\n",
      "\n",
      "Test set:\n",
      "Earliest timestamp: 2019-11-15 00:00:00\n",
      "Latest timestamp: 2019-11-15 23:59:43\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set:\")\n",
    "print(\"Earliest timestamp:\", df_train['timestamp'].min())\n",
    "print(\"Latest timestamp:\", df_train['timestamp'].max())\n",
    "\n",
    "print(\"\\nDev set:\")\n",
    "print(\"Earliest timestamp:\", df_dev['timestamp'].min())\n",
    "print(\"Latest timestamp:\", df_dev['timestamp'].max())\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(\"Earliest timestamp:\", df_test['timestamp'].min())\n",
    "print(\"Latest timestamp:\", df_test['timestamp'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbcc0a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_save(df, path):\n",
    "    # Split df into groups by date (each group is a single day)\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "    train_groups_by_day = df.groupby('date')\n",
    "    article_groups_by_day = {}\n",
    "    for i, group in tqdm(train_groups_by_day):\n",
    "        impression_rows = group['impressions'].apply(lambda x: [int(i.split('-')[0][1:]) for i in x.split()]).to_list()\n",
    "        unique_articles = set()\n",
    "        for impressions in impression_rows:\n",
    "            unique_articles.update(set(impressions))\n",
    "        article_groups_by_day[str(i)] = unique_articles\n",
    "    return article_groups_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6774385c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1791a0b73a4a37ba1d800c7a8f70ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7063c7632694c5f8cf1e8e8db28c373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbbefd189d24a0a9ed7786b8526b0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_article_groups = split_and_save(df_train, MIND_train_path)\n",
    "test_article_groups = split_and_save(df_test, MIND_test_path)\n",
    "dev_article_groups = split_and_save(df_dev, MIND_dev_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07322edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'client' in locals() and client is not None:\n",
    "    try:\n",
    "        client.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "client = MilvusClient(str(aspect_vector_dir / \"aspect_data_new.db\"))\n",
    "def create_collection(collection_name: str, dimension: int):\n",
    "    \"\"\"\n",
    "    Create a collection in Milvus.\n",
    "    \"\"\"\n",
    "    schema = CollectionSchema(\n",
    "        fields=[\n",
    "            FieldSchema(name='nid', dtype=DataType.INT64, is_primary=True),\n",
    "            FieldSchema(name='vector', dtype=DataType.FLOAT_VECTOR, dim=dimension),\n",
    "        ]\n",
    "    )\n",
    "    index_params = client.prepare_index_params()\n",
    "    index_params.add_index(\n",
    "        field_name=\"vector\", metric_type=\"IP\", index_type=\"AUTOINDEX\", params={}\n",
    "    )\n",
    "    if client.has_collection(collection_name):\n",
    "        client.drop_collection(collection_name)\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        schema=schema,\n",
    "        index_params=index_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d9f9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5120,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_aspect_vectors['dev'][88753]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77e6194a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee1ea81a86441b8befd76674a67dd53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dev with 76167 vectors on date 2019-11-14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b2e0f93f40423b8801dd0459548438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inserting dev_mind_2019_11_14:   0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test with 72023 vectors on date 2019-11-15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8b5c2523584132943260941fb98083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inserting test_mind_2019_11_15:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, vectors in tqdm(combined_aspect_vectors.items()):\n",
    "    df = {}\n",
    "    if key == 'train':\n",
    "        df = train_article_groups\n",
    "    elif key == 'dev':\n",
    "        df = dev_article_groups\n",
    "    elif key == 'test':\n",
    "        df = test_article_groups\n",
    "    for date in df.keys():\n",
    "        print(f\"Processing {key} with {len(vectors)} vectors on date {date}\")\n",
    "        collection_name = f\"{key}_mind_{date.replace('-', '_')}\"\n",
    "        create_collection(collection_name, len(next(iter(vectors.values()))))\n",
    "        keys = list(vectors.keys())\n",
    "        batch_size = 1000\n",
    "        for i in trange(0, len(keys), batch_size, desc=f\"Inserting {collection_name}\"):\n",
    "            batch_keys = keys[i:i + batch_size]\n",
    "            batch_vectors = {k: vectors[k] for k in batch_keys if k in df[date]}\n",
    "            # Prepare data for insertion\n",
    "            data = [\n",
    "                {\"nid\": nid, \"vector\": vector.tolist()} for nid, vector in batch_vectors.items()\n",
    "            ]\n",
    "            client.insert(collection_name=collection_name, data=data)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a94a7067",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24a47039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'dev_mind_cat_aspect_2019_11_14' size: 8705\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "collection_name = \"dev_mind_cat_aspect_2019_11_14\"\n",
    "\n",
    "# Check the number of entities in the collection\n",
    "collection_stats = client.get_collection_stats(collection_name)\n",
    "print(f\"Collection '{collection_name}' size:\", collection_stats[\"row_count\"])\n",
    "# Get top 3 items from 'dev_mind_cat_aspect_2019_11_14' collection in Milvus\n",
    "# Assuming the collection contains a 'vector' field and you want the top 3 by L2 norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb096ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_article_groups = pd.read_csv(MIND_train_path / 'grouped_behaviors.tsv', sep='\\t', header=None, index_col=0)\n",
    "df_train_article_groups.columns = ['Date', 'Articles']\n",
    "df_dev_article_groups = pd.read_csv(MIND_dev_path / 'grouped_behaviors.tsv', sep='\\t', header=None, index_col=0)\n",
    "df_dev_article_groups.columns = ['Date', 'Articles']\n",
    "df_test_article_groups = pd.read_csv(MIND_test_path / 'grouped_behaviors.tsv', sep='\\t', header=None, index_col=0)\n",
    "df_test_article_groups.columns = ['Date', 'Articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e7e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_article_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf033b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
